{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston,price = load_boston(return_X_y=True)\n",
    "\n",
    "Y=price.reshape(506,)\n",
    "X=boston.astype(float)\n",
    "print (X.shape)\n",
    "print (Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, init='normal' ,activation='relu'))\n",
    "model.add(Dense(15, init='normal', activation='relu'))\n",
    "model.add(Dense(1, init='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "506/506 [==============================] - 0s - loss: 478.9033 - mean_absolute_error: 19.4927     \n",
      "Epoch 2/300\n",
      "506/506 [==============================] - 0s - loss: 139.8446 - mean_absolute_error: 8.9755     \n",
      "Epoch 3/300\n",
      "506/506 [==============================] - 0s - loss: 104.9336 - mean_absolute_error: 7.5282     \n",
      "Epoch 4/300\n",
      "506/506 [==============================] - 0s - loss: 87.2788 - mean_absolute_error: 6.7434     \n",
      "Epoch 5/300\n",
      "506/506 [==============================] - 0s - loss: 74.0565 - mean_absolute_error: 6.1394     \n",
      "Epoch 6/300\n",
      "506/506 [==============================] - 0s - loss: 69.7227 - mean_absolute_error: 6.0138     \n",
      "Epoch 7/300\n",
      "506/506 [==============================] - 0s - loss: 66.0468 - mean_absolute_error: 5.7924     \n",
      "Epoch 8/300\n",
      "506/506 [==============================] - 0s - loss: 61.5399 - mean_absolute_error: 5.5432     \n",
      "Epoch 9/300\n",
      "506/506 [==============================] - 0s - loss: 59.0228 - mean_absolute_error: 5.4458     \n",
      "Epoch 10/300\n",
      "506/506 [==============================] - 0s - loss: 58.5421 - mean_absolute_error: 5.3470     \n",
      "Epoch 11/300\n",
      "506/506 [==============================] - 0s - loss: 56.9495 - mean_absolute_error: 5.2141     \n",
      "Epoch 12/300\n",
      "506/506 [==============================] - 0s - loss: 55.7530 - mean_absolute_error: 5.2837     \n",
      "Epoch 13/300\n",
      "506/506 [==============================] - 0s - loss: 54.4728 - mean_absolute_error: 5.0759     \n",
      "Epoch 14/300\n",
      "506/506 [==============================] - 0s - loss: 53.1800 - mean_absolute_error: 5.2288     \n",
      "Epoch 15/300\n",
      "506/506 [==============================] - 0s - loss: 51.9785 - mean_absolute_error: 5.0283     \n",
      "Epoch 16/300\n",
      "506/506 [==============================] - 0s - loss: 50.2959 - mean_absolute_error: 4.9041     \n",
      "Epoch 17/300\n",
      "506/506 [==============================] - 0s - loss: 49.9867 - mean_absolute_error: 4.9857     \n",
      "Epoch 18/300\n",
      "506/506 [==============================] - 0s - loss: 49.7424 - mean_absolute_error: 4.9761     \n",
      "Epoch 19/300\n",
      "506/506 [==============================] - 0s - loss: 47.1852 - mean_absolute_error: 4.7949     \n",
      "Epoch 20/300\n",
      "506/506 [==============================] - 0s - loss: 46.2444 - mean_absolute_error: 4.7380     \n",
      "Epoch 21/300\n",
      "506/506 [==============================] - 0s - loss: 44.4416 - mean_absolute_error: 4.7365     \n",
      "Epoch 22/300\n",
      "506/506 [==============================] - 0s - loss: 43.4692 - mean_absolute_error: 4.6319     \n",
      "Epoch 23/300\n",
      "506/506 [==============================] - 0s - loss: 42.4931 - mean_absolute_error: 4.5167     \n",
      "Epoch 24/300\n",
      "506/506 [==============================] - 0s - loss: 42.0765 - mean_absolute_error: 4.5896     \n",
      "Epoch 25/300\n",
      "506/506 [==============================] - 0s - loss: 42.0835 - mean_absolute_error: 4.6103     \n",
      "Epoch 26/300\n",
      "506/506 [==============================] - 0s - loss: 38.6889 - mean_absolute_error: 4.4033     \n",
      "Epoch 27/300\n",
      "506/506 [==============================] - 0s - loss: 37.9227 - mean_absolute_error: 4.3169     \n",
      "Epoch 28/300\n",
      "506/506 [==============================] - 0s - loss: 37.3575 - mean_absolute_error: 4.4417     \n",
      "Epoch 29/300\n",
      "506/506 [==============================] - 0s - loss: 35.8271 - mean_absolute_error: 4.2632     \n",
      "Epoch 30/300\n",
      "506/506 [==============================] - 0s - loss: 36.7422 - mean_absolute_error: 4.4046     \n",
      "Epoch 31/300\n",
      "506/506 [==============================] - 0s - loss: 34.7995 - mean_absolute_error: 4.2379     \n",
      "Epoch 32/300\n",
      "506/506 [==============================] - 0s - loss: 33.5122 - mean_absolute_error: 4.1943     \n",
      "Epoch 33/300\n",
      "506/506 [==============================] - 0s - loss: 33.7528 - mean_absolute_error: 4.1952     \n",
      "Epoch 34/300\n",
      "506/506 [==============================] - 0s - loss: 33.6200 - mean_absolute_error: 4.2610     \n",
      "Epoch 35/300\n",
      "506/506 [==============================] - 0s - loss: 33.2068 - mean_absolute_error: 4.2919     \n",
      "Epoch 36/300\n",
      "506/506 [==============================] - 0s - loss: 31.1912 - mean_absolute_error: 4.1285     \n",
      "Epoch 37/300\n",
      "506/506 [==============================] - 0s - loss: 30.4233 - mean_absolute_error: 4.0765     \n",
      "Epoch 38/300\n",
      "506/506 [==============================] - 0s - loss: 30.1796 - mean_absolute_error: 4.1328     \n",
      "Epoch 39/300\n",
      "506/506 [==============================] - 0s - loss: 30.9631 - mean_absolute_error: 4.0930     \n",
      "Epoch 40/300\n",
      "506/506 [==============================] - 0s - loss: 28.7735 - mean_absolute_error: 3.9880     \n",
      "Epoch 41/300\n",
      "506/506 [==============================] - 0s - loss: 28.5124 - mean_absolute_error: 3.9523     \n",
      "Epoch 42/300\n",
      "506/506 [==============================] - 0s - loss: 27.5190 - mean_absolute_error: 3.8375     \n",
      "Epoch 43/300\n",
      "506/506 [==============================] - 0s - loss: 28.3025 - mean_absolute_error: 3.8607     \n",
      "Epoch 44/300\n",
      "506/506 [==============================] - 0s - loss: 27.3806 - mean_absolute_error: 3.8926     \n",
      "Epoch 45/300\n",
      "506/506 [==============================] - 0s - loss: 26.0646 - mean_absolute_error: 3.7767     \n",
      "Epoch 46/300\n",
      "506/506 [==============================] - 0s - loss: 25.5358 - mean_absolute_error: 3.7534     \n",
      "Epoch 47/300\n",
      "506/506 [==============================] - 0s - loss: 25.4201 - mean_absolute_error: 3.6599     \n",
      "Epoch 48/300\n",
      "506/506 [==============================] - 0s - loss: 25.6241 - mean_absolute_error: 3.7052     \n",
      "Epoch 49/300\n",
      "506/506 [==============================] - 0s - loss: 25.0675 - mean_absolute_error: 3.6672     \n",
      "Epoch 50/300\n",
      "506/506 [==============================] - 0s - loss: 24.5449 - mean_absolute_error: 3.6623     \n",
      "Epoch 51/300\n",
      "506/506 [==============================] - 0s - loss: 26.6006 - mean_absolute_error: 3.8408     \n",
      "Epoch 52/300\n",
      "506/506 [==============================] - 0s - loss: 23.9875 - mean_absolute_error: 3.6032     \n",
      "Epoch 53/300\n",
      "506/506 [==============================] - 0s - loss: 23.6060 - mean_absolute_error: 3.5976     \n",
      "Epoch 54/300\n",
      "506/506 [==============================] - 0s - loss: 24.6815 - mean_absolute_error: 3.6025     \n",
      "Epoch 55/300\n",
      "506/506 [==============================] - 0s - loss: 23.2128 - mean_absolute_error: 3.5502     \n",
      "Epoch 56/300\n",
      "506/506 [==============================] - 0s - loss: 23.6007 - mean_absolute_error: 3.5850     \n",
      "Epoch 57/300\n",
      "506/506 [==============================] - 0s - loss: 22.4123 - mean_absolute_error: 3.4757     \n",
      "Epoch 58/300\n",
      "506/506 [==============================] - 0s - loss: 24.1032 - mean_absolute_error: 3.6199     \n",
      "Epoch 59/300\n",
      "506/506 [==============================] - 0s - loss: 22.0300 - mean_absolute_error: 3.4279     \n",
      "Epoch 60/300\n",
      "506/506 [==============================] - 0s - loss: 21.0487 - mean_absolute_error: 3.3450     \n",
      "Epoch 61/300\n",
      "506/506 [==============================] - 0s - loss: 21.9993 - mean_absolute_error: 3.4034     \n",
      "Epoch 62/300\n",
      "506/506 [==============================] - 0s - loss: 21.5243 - mean_absolute_error: 3.3947     \n",
      "Epoch 63/300\n",
      "506/506 [==============================] - 0s - loss: 22.0840 - mean_absolute_error: 3.4713     \n",
      "Epoch 64/300\n",
      "506/506 [==============================] - 0s - loss: 21.4185 - mean_absolute_error: 3.3979     \n",
      "Epoch 65/300\n",
      "506/506 [==============================] - 0s - loss: 21.6443 - mean_absolute_error: 3.2883     \n",
      "Epoch 66/300\n",
      "506/506 [==============================] - 0s - loss: 22.8187 - mean_absolute_error: 3.4938     \n",
      "Epoch 67/300\n",
      "506/506 [==============================] - 0s - loss: 22.2280 - mean_absolute_error: 3.4277     \n",
      "Epoch 68/300\n",
      "506/506 [==============================] - 0s - loss: 21.9497 - mean_absolute_error: 3.3392     \n",
      "Epoch 69/300\n",
      "506/506 [==============================] - 0s - loss: 19.9676 - mean_absolute_error: 3.2474     \n",
      "Epoch 70/300\n",
      "506/506 [==============================] - 0s - loss: 20.8456 - mean_absolute_error: 3.2433     \n",
      "Epoch 71/300\n",
      "506/506 [==============================] - 0s - loss: 21.4479 - mean_absolute_error: 3.3140     \n",
      "Epoch 72/300\n",
      "506/506 [==============================] - 0s - loss: 19.9828 - mean_absolute_error: 3.2128     \n",
      "Epoch 73/300\n",
      "506/506 [==============================] - 0s - loss: 19.8876 - mean_absolute_error: 3.2769     \n",
      "Epoch 74/300\n",
      "506/506 [==============================] - 0s - loss: 19.3423 - mean_absolute_error: 3.2110     \n",
      "Epoch 75/300\n",
      "506/506 [==============================] - 0s - loss: 19.5333 - mean_absolute_error: 3.2018     \n",
      "Epoch 76/300\n",
      "506/506 [==============================] - 0s - loss: 21.7521 - mean_absolute_error: 3.3310     \n",
      "Epoch 77/300\n",
      "506/506 [==============================] - 0s - loss: 20.4435 - mean_absolute_error: 3.3158     \n",
      "Epoch 78/300\n",
      "506/506 [==============================] - 0s - loss: 19.7642 - mean_absolute_error: 3.1778     \n",
      "Epoch 79/300\n",
      "506/506 [==============================] - 0s - loss: 21.8711 - mean_absolute_error: 3.4060     \n",
      "Epoch 80/300\n",
      "506/506 [==============================] - 0s - loss: 19.1616 - mean_absolute_error: 3.1943     \n",
      "Epoch 81/300\n",
      "506/506 [==============================] - 0s - loss: 19.5783 - mean_absolute_error: 3.1992     \n",
      "Epoch 82/300\n",
      "506/506 [==============================] - 0s - loss: 19.9803 - mean_absolute_error: 3.2717     \n",
      "Epoch 83/300\n",
      "506/506 [==============================] - 0s - loss: 19.1533 - mean_absolute_error: 3.1075     \n",
      "Epoch 84/300\n",
      "506/506 [==============================] - 0s - loss: 19.1925 - mean_absolute_error: 3.1322     \n",
      "Epoch 85/300\n",
      "506/506 [==============================] - 0s - loss: 20.4462 - mean_absolute_error: 3.3062     \n",
      "Epoch 86/300\n",
      "506/506 [==============================] - 0s - loss: 19.5432 - mean_absolute_error: 3.2546     \n",
      "Epoch 87/300\n",
      "506/506 [==============================] - 0s - loss: 20.1383 - mean_absolute_error: 3.2154     \n",
      "Epoch 88/300\n",
      "506/506 [==============================] - 0s - loss: 19.4265 - mean_absolute_error: 3.1887     \n",
      "Epoch 89/300\n",
      "506/506 [==============================] - 0s - loss: 19.9125 - mean_absolute_error: 3.1845     \n",
      "Epoch 90/300\n",
      "506/506 [==============================] - 0s - loss: 18.0286 - mean_absolute_error: 3.0378     \n",
      "Epoch 91/300\n",
      "506/506 [==============================] - 0s - loss: 23.5581 - mean_absolute_error: 3.5385     \n",
      "Epoch 92/300\n",
      "506/506 [==============================] - 0s - loss: 18.7714 - mean_absolute_error: 3.1277     \n",
      "Epoch 93/300\n",
      "506/506 [==============================] - 0s - loss: 18.7105 - mean_absolute_error: 3.1810     \n",
      "Epoch 94/300\n",
      "506/506 [==============================] - 0s - loss: 20.5702 - mean_absolute_error: 3.2015     \n",
      "Epoch 95/300\n",
      "506/506 [==============================] - 0s - loss: 20.6915 - mean_absolute_error: 3.3027     \n",
      "Epoch 96/300\n",
      "506/506 [==============================] - 0s - loss: 18.5275 - mean_absolute_error: 3.1318     \n",
      "Epoch 97/300\n",
      "506/506 [==============================] - 0s - loss: 17.4777 - mean_absolute_error: 2.9963     \n",
      "Epoch 98/300\n",
      "506/506 [==============================] - 0s - loss: 20.5626 - mean_absolute_error: 3.2744     \n",
      "Epoch 99/300\n",
      "506/506 [==============================] - 0s - loss: 18.4044 - mean_absolute_error: 3.1406     \n",
      "Epoch 100/300\n",
      "506/506 [==============================] - 0s - loss: 18.3394 - mean_absolute_error: 3.0979     \n",
      "Epoch 101/300\n",
      "506/506 [==============================] - 0s - loss: 18.3637 - mean_absolute_error: 3.0367     \n",
      "Epoch 102/300\n",
      "506/506 [==============================] - 0s - loss: 17.0852 - mean_absolute_error: 3.0177     \n",
      "Epoch 103/300\n",
      "506/506 [==============================] - 0s - loss: 18.8058 - mean_absolute_error: 3.0629     \n",
      "Epoch 104/300\n",
      "506/506 [==============================] - 0s - loss: 18.7942 - mean_absolute_error: 3.1873     \n",
      "Epoch 105/300\n",
      "506/506 [==============================] - 0s - loss: 18.8917 - mean_absolute_error: 3.1244     \n",
      "Epoch 106/300\n",
      "506/506 [==============================] - 0s - loss: 18.1629 - mean_absolute_error: 3.0604     \n",
      "Epoch 107/300\n",
      "506/506 [==============================] - 0s - loss: 18.5835 - mean_absolute_error: 3.1082     \n",
      "Epoch 108/300\n",
      "506/506 [==============================] - 0s - loss: 19.0318 - mean_absolute_error: 3.0559     \n",
      "Epoch 109/300\n",
      "506/506 [==============================] - 0s - loss: 17.9491 - mean_absolute_error: 3.0277     \n",
      "Epoch 110/300\n",
      "506/506 [==============================] - 0s - loss: 18.6932 - mean_absolute_error: 3.1592     \n",
      "Epoch 111/300\n",
      "506/506 [==============================] - 0s - loss: 21.2573 - mean_absolute_error: 3.3158     \n",
      "Epoch 112/300\n",
      "506/506 [==============================] - 0s - loss: 17.7877 - mean_absolute_error: 3.0051     \n",
      "Epoch 113/300\n",
      "506/506 [==============================] - 0s - loss: 16.9149 - mean_absolute_error: 2.9677     \n",
      "Epoch 114/300\n",
      "506/506 [==============================] - 0s - loss: 17.2243 - mean_absolute_error: 2.9620     \n",
      "Epoch 115/300\n",
      "506/506 [==============================] - 0s - loss: 17.1219 - mean_absolute_error: 2.9466     \n",
      "Epoch 116/300\n",
      "506/506 [==============================] - 0s - loss: 19.1297 - mean_absolute_error: 3.1073     \n",
      "Epoch 117/300\n",
      "506/506 [==============================] - 0s - loss: 18.3750 - mean_absolute_error: 3.1142     \n",
      "Epoch 118/300\n",
      "506/506 [==============================] - 0s - loss: 21.9290 - mean_absolute_error: 3.2560     \n",
      "Epoch 119/300\n",
      "506/506 [==============================] - 0s - loss: 17.4537 - mean_absolute_error: 2.9813     \n",
      "Epoch 120/300\n",
      "506/506 [==============================] - 0s - loss: 18.6350 - mean_absolute_error: 3.0035     \n",
      "Epoch 121/300\n",
      "506/506 [==============================] - 0s - loss: 19.0692 - mean_absolute_error: 3.1276     \n",
      "Epoch 122/300\n",
      "506/506 [==============================] - 0s - loss: 18.2887 - mean_absolute_error: 3.0628     \n",
      "Epoch 123/300\n",
      "506/506 [==============================] - 0s - loss: 18.1175 - mean_absolute_error: 3.0122     \n",
      "Epoch 124/300\n",
      "506/506 [==============================] - 0s - loss: 17.4286 - mean_absolute_error: 2.9992     \n",
      "Epoch 125/300\n",
      "506/506 [==============================] - 0s - loss: 17.5487 - mean_absolute_error: 2.9831     \n",
      "Epoch 126/300\n",
      "506/506 [==============================] - 0s - loss: 17.9842 - mean_absolute_error: 3.0775     \n",
      "Epoch 127/300\n",
      "506/506 [==============================] - 0s - loss: 18.6052 - mean_absolute_error: 3.0016     \n",
      "Epoch 128/300\n",
      "506/506 [==============================] - 0s - loss: 18.4398 - mean_absolute_error: 3.0763     \n",
      "Epoch 129/300\n",
      "506/506 [==============================] - 0s - loss: 17.1999 - mean_absolute_error: 2.9500     \n",
      "Epoch 130/300\n",
      "506/506 [==============================] - 0s - loss: 18.0391 - mean_absolute_error: 3.0168     \n",
      "Epoch 131/300\n",
      "506/506 [==============================] - 0s - loss: 17.4211 - mean_absolute_error: 2.9997     \n",
      "Epoch 132/300\n",
      "506/506 [==============================] - 0s - loss: 17.2904 - mean_absolute_error: 2.9928     \n",
      "Epoch 133/300\n",
      "506/506 [==============================] - 0s - loss: 16.9649 - mean_absolute_error: 2.9982     \n",
      "Epoch 134/300\n",
      "506/506 [==============================] - 0s - loss: 17.9751 - mean_absolute_error: 3.0874     \n",
      "Epoch 135/300\n",
      "506/506 [==============================] - 0s - loss: 18.3526 - mean_absolute_error: 3.0173     \n",
      "Epoch 136/300\n",
      "506/506 [==============================] - 0s - loss: 18.6415 - mean_absolute_error: 3.0402     \n",
      "Epoch 137/300\n",
      "506/506 [==============================] - 0s - loss: 16.5012 - mean_absolute_error: 2.9007     \n",
      "Epoch 138/300\n",
      "506/506 [==============================] - 0s - loss: 16.8673 - mean_absolute_error: 2.9546     \n",
      "Epoch 139/300\n",
      "506/506 [==============================] - 0s - loss: 16.8749 - mean_absolute_error: 2.9298     \n",
      "Epoch 140/300\n",
      "506/506 [==============================] - 0s - loss: 16.1969 - mean_absolute_error: 2.8560     \n",
      "Epoch 141/300\n",
      "506/506 [==============================] - 0s - loss: 17.0560 - mean_absolute_error: 2.9769     \n",
      "Epoch 142/300\n",
      "506/506 [==============================] - 0s - loss: 18.4165 - mean_absolute_error: 3.0539     \n",
      "Epoch 143/300\n",
      "506/506 [==============================] - 0s - loss: 17.5621 - mean_absolute_error: 3.0090     \n",
      "Epoch 144/300\n",
      "506/506 [==============================] - 0s - loss: 17.7945 - mean_absolute_error: 2.9920     \n",
      "Epoch 145/300\n",
      "506/506 [==============================] - 0s - loss: 17.6057 - mean_absolute_error: 3.0015     \n",
      "Epoch 146/300\n",
      "506/506 [==============================] - 0s - loss: 20.5880 - mean_absolute_error: 3.1920     \n",
      "Epoch 147/300\n",
      "506/506 [==============================] - 0s - loss: 18.9006 - mean_absolute_error: 3.0939     \n",
      "Epoch 148/300\n",
      "506/506 [==============================] - 0s - loss: 17.5336 - mean_absolute_error: 2.9188     \n",
      "Epoch 149/300\n",
      "506/506 [==============================] - 0s - loss: 17.1281 - mean_absolute_error: 2.9209     \n",
      "Epoch 150/300\n",
      "506/506 [==============================] - 0s - loss: 17.5195 - mean_absolute_error: 3.0183     \n",
      "Epoch 151/300\n",
      "506/506 [==============================] - 0s - loss: 17.2905 - mean_absolute_error: 2.9281     \n",
      "Epoch 152/300\n",
      "506/506 [==============================] - 0s - loss: 16.0190 - mean_absolute_error: 2.8526     \n",
      "Epoch 153/300\n",
      "506/506 [==============================] - 0s - loss: 16.9134 - mean_absolute_error: 2.9197     \n",
      "Epoch 154/300\n",
      "506/506 [==============================] - 0s - loss: 17.7852 - mean_absolute_error: 2.9812     \n",
      "Epoch 155/300\n",
      "506/506 [==============================] - 0s - loss: 17.2830 - mean_absolute_error: 2.9163     \n",
      "Epoch 156/300\n",
      "506/506 [==============================] - 0s - loss: 16.3973 - mean_absolute_error: 2.9164     \n",
      "Epoch 157/300\n",
      "506/506 [==============================] - 0s - loss: 16.6562 - mean_absolute_error: 2.9686     \n",
      "Epoch 158/300\n",
      "506/506 [==============================] - 0s - loss: 16.7146 - mean_absolute_error: 2.9421     \n",
      "Epoch 159/300\n",
      "506/506 [==============================] - 0s - loss: 16.6660 - mean_absolute_error: 2.8916     \n",
      "Epoch 160/300\n",
      "506/506 [==============================] - 0s - loss: 16.5164 - mean_absolute_error: 2.9150     \n",
      "Epoch 161/300\n",
      "506/506 [==============================] - 0s - loss: 16.7182 - mean_absolute_error: 2.9520     \n",
      "Epoch 162/300\n",
      "506/506 [==============================] - 0s - loss: 16.6149 - mean_absolute_error: 2.9211     \n",
      "Epoch 163/300\n",
      "506/506 [==============================] - 0s - loss: 17.9093 - mean_absolute_error: 3.0681     \n",
      "Epoch 164/300\n",
      "506/506 [==============================] - 0s - loss: 16.9867 - mean_absolute_error: 2.9370     \n",
      "Epoch 165/300\n",
      "506/506 [==============================] - 0s - loss: 16.6695 - mean_absolute_error: 2.9029     \n",
      "Epoch 166/300\n",
      "506/506 [==============================] - 0s - loss: 18.4667 - mean_absolute_error: 3.0577     \n",
      "Epoch 167/300\n",
      "506/506 [==============================] - 0s - loss: 18.6142 - mean_absolute_error: 3.0446     \n",
      "Epoch 168/300\n",
      "506/506 [==============================] - 0s - loss: 16.7507 - mean_absolute_error: 2.9466     \n",
      "Epoch 169/300\n",
      "506/506 [==============================] - 0s - loss: 16.8854 - mean_absolute_error: 2.9180     \n",
      "Epoch 170/300\n",
      "506/506 [==============================] - 0s - loss: 16.0861 - mean_absolute_error: 2.8527     \n",
      "Epoch 171/300\n",
      "506/506 [==============================] - 0s - loss: 16.6933 - mean_absolute_error: 2.9078     \n",
      "Epoch 172/300\n",
      "506/506 [==============================] - 0s - loss: 15.5809 - mean_absolute_error: 2.8234     \n",
      "Epoch 173/300\n",
      "506/506 [==============================] - 0s - loss: 17.3449 - mean_absolute_error: 2.9694     \n",
      "Epoch 174/300\n",
      "506/506 [==============================] - 0s - loss: 16.3884 - mean_absolute_error: 2.8963     \n",
      "Epoch 175/300\n",
      "506/506 [==============================] - 0s - loss: 16.4648 - mean_absolute_error: 2.8428     \n",
      "Epoch 176/300\n",
      "506/506 [==============================] - 0s - loss: 15.8304 - mean_absolute_error: 2.8283     \n",
      "Epoch 177/300\n",
      "506/506 [==============================] - 0s - loss: 16.4247 - mean_absolute_error: 2.9049     \n",
      "Epoch 178/300\n",
      "506/506 [==============================] - 0s - loss: 17.0054 - mean_absolute_error: 2.9658     \n",
      "Epoch 179/300\n",
      "506/506 [==============================] - 0s - loss: 16.0178 - mean_absolute_error: 2.8713     \n",
      "Epoch 180/300\n",
      "506/506 [==============================] - 0s - loss: 16.2776 - mean_absolute_error: 2.9899     \n",
      "Epoch 181/300\n",
      "506/506 [==============================] - 0s - loss: 16.4557 - mean_absolute_error: 2.9130     \n",
      "Epoch 182/300\n",
      "506/506 [==============================] - 0s - loss: 16.7160 - mean_absolute_error: 2.9257     \n",
      "Epoch 183/300\n",
      "506/506 [==============================] - 0s - loss: 15.6553 - mean_absolute_error: 2.7932     \n",
      "Epoch 184/300\n",
      "506/506 [==============================] - 0s - loss: 17.7622 - mean_absolute_error: 3.0491     \n",
      "Epoch 185/300\n",
      "506/506 [==============================] - 0s - loss: 18.3891 - mean_absolute_error: 3.0402     \n",
      "Epoch 186/300\n",
      "506/506 [==============================] - 0s - loss: 16.2390 - mean_absolute_error: 2.9145     \n",
      "Epoch 187/300\n",
      "506/506 [==============================] - 0s - loss: 17.2462 - mean_absolute_error: 2.9762     \n",
      "Epoch 188/300\n",
      "506/506 [==============================] - 0s - loss: 16.3181 - mean_absolute_error: 2.8628     \n",
      "Epoch 189/300\n",
      "506/506 [==============================] - 0s - loss: 16.0083 - mean_absolute_error: 2.8939     \n",
      "Epoch 190/300\n",
      "506/506 [==============================] - 0s - loss: 15.7059 - mean_absolute_error: 2.9094     \n",
      "Epoch 191/300\n",
      "506/506 [==============================] - 0s - loss: 15.8482 - mean_absolute_error: 2.8559     \n",
      "Epoch 192/300\n",
      "506/506 [==============================] - 0s - loss: 17.2393 - mean_absolute_error: 2.9725     \n",
      "Epoch 193/300\n",
      "506/506 [==============================] - 0s - loss: 15.8806 - mean_absolute_error: 2.8539     \n",
      "Epoch 194/300\n",
      "506/506 [==============================] - 0s - loss: 15.6418 - mean_absolute_error: 2.7900     \n",
      "Epoch 195/300\n",
      "506/506 [==============================] - 0s - loss: 17.2510 - mean_absolute_error: 3.0131     \n",
      "Epoch 196/300\n",
      "506/506 [==============================] - 0s - loss: 15.9728 - mean_absolute_error: 2.8609     \n",
      "Epoch 197/300\n",
      "506/506 [==============================] - 0s - loss: 17.6131 - mean_absolute_error: 3.0298     \n",
      "Epoch 198/300\n",
      "506/506 [==============================] - 0s - loss: 16.0620 - mean_absolute_error: 2.7791     \n",
      "Epoch 199/300\n",
      "506/506 [==============================] - 0s - loss: 16.8637 - mean_absolute_error: 2.9886     \n",
      "Epoch 200/300\n",
      "506/506 [==============================] - 0s - loss: 15.1928 - mean_absolute_error: 2.7990     \n",
      "Epoch 201/300\n",
      "506/506 [==============================] - 0s - loss: 17.9854 - mean_absolute_error: 2.9561     \n",
      "Epoch 202/300\n",
      "506/506 [==============================] - 0s - loss: 16.5381 - mean_absolute_error: 2.9003     \n",
      "Epoch 203/300\n",
      "506/506 [==============================] - 0s - loss: 16.6988 - mean_absolute_error: 2.8675     \n",
      "Epoch 204/300\n",
      "506/506 [==============================] - 0s - loss: 15.8205 - mean_absolute_error: 2.8552     \n",
      "Epoch 205/300\n",
      "506/506 [==============================] - 0s - loss: 15.3477 - mean_absolute_error: 2.8038     \n",
      "Epoch 206/300\n",
      "506/506 [==============================] - 0s - loss: 15.8363 - mean_absolute_error: 2.9129     \n",
      "Epoch 207/300\n",
      "506/506 [==============================] - 0s - loss: 16.3034 - mean_absolute_error: 2.9006     \n",
      "Epoch 208/300\n",
      "506/506 [==============================] - 0s - loss: 15.6834 - mean_absolute_error: 2.8366     \n",
      "Epoch 209/300\n",
      "506/506 [==============================] - 0s - loss: 16.0450 - mean_absolute_error: 2.8523     \n",
      "Epoch 210/300\n",
      "506/506 [==============================] - 0s - loss: 17.2540 - mean_absolute_error: 3.0471     \n",
      "Epoch 211/300\n",
      "506/506 [==============================] - 0s - loss: 15.7059 - mean_absolute_error: 2.8121     \n",
      "Epoch 212/300\n",
      "506/506 [==============================] - 0s - loss: 15.1317 - mean_absolute_error: 2.7858     \n",
      "Epoch 213/300\n",
      "506/506 [==============================] - 0s - loss: 14.9338 - mean_absolute_error: 2.8057     \n",
      "Epoch 214/300\n",
      "506/506 [==============================] - 0s - loss: 15.1245 - mean_absolute_error: 2.8338     \n",
      "Epoch 215/300\n",
      "506/506 [==============================] - 0s - loss: 16.1507 - mean_absolute_error: 2.9045     \n",
      "Epoch 216/300\n",
      "506/506 [==============================] - 0s - loss: 14.7004 - mean_absolute_error: 2.7735     \n",
      "Epoch 217/300\n",
      "506/506 [==============================] - 0s - loss: 15.2203 - mean_absolute_error: 2.7610     \n",
      "Epoch 218/300\n",
      "506/506 [==============================] - 0s - loss: 15.3034 - mean_absolute_error: 2.7842     \n",
      "Epoch 219/300\n",
      "506/506 [==============================] - 0s - loss: 15.3043 - mean_absolute_error: 2.7941     \n",
      "Epoch 220/300\n",
      "506/506 [==============================] - 0s - loss: 15.1036 - mean_absolute_error: 2.7903     \n",
      "Epoch 221/300\n",
      "506/506 [==============================] - 0s - loss: 16.2738 - mean_absolute_error: 2.8910     \n",
      "Epoch 222/300\n",
      "506/506 [==============================] - 0s - loss: 14.4992 - mean_absolute_error: 2.7200     \n",
      "Epoch 223/300\n",
      "506/506 [==============================] - 0s - loss: 15.2727 - mean_absolute_error: 2.7883     \n",
      "Epoch 224/300\n",
      "506/506 [==============================] - 0s - loss: 15.7525 - mean_absolute_error: 2.8663     \n",
      "Epoch 225/300\n",
      "506/506 [==============================] - 0s - loss: 16.4402 - mean_absolute_error: 2.9033     \n",
      "Epoch 226/300\n",
      "506/506 [==============================] - 0s - loss: 15.3379 - mean_absolute_error: 2.8065     \n",
      "Epoch 227/300\n",
      "506/506 [==============================] - 0s - loss: 14.6390 - mean_absolute_error: 2.7526     \n",
      "Epoch 228/300\n",
      "506/506 [==============================] - 0s - loss: 15.1510 - mean_absolute_error: 2.7617     \n",
      "Epoch 229/300\n",
      "506/506 [==============================] - 0s - loss: 16.5987 - mean_absolute_error: 2.8824     \n",
      "Epoch 230/300\n",
      "506/506 [==============================] - 0s - loss: 15.1204 - mean_absolute_error: 2.7571     \n",
      "Epoch 231/300\n",
      "506/506 [==============================] - 0s - loss: 14.6313 - mean_absolute_error: 2.7362     \n",
      "Epoch 232/300\n",
      "506/506 [==============================] - 0s - loss: 15.8196 - mean_absolute_error: 2.8834     \n",
      "Epoch 233/300\n",
      "506/506 [==============================] - 0s - loss: 17.8408 - mean_absolute_error: 3.0245     \n",
      "Epoch 234/300\n",
      "506/506 [==============================] - 0s - loss: 15.8758 - mean_absolute_error: 2.8006     \n",
      "Epoch 235/300\n",
      "506/506 [==============================] - 0s - loss: 14.4304 - mean_absolute_error: 2.7128     \n",
      "Epoch 236/300\n",
      "506/506 [==============================] - 0s - loss: 15.5429 - mean_absolute_error: 2.8154     \n",
      "Epoch 237/300\n",
      "506/506 [==============================] - 0s - loss: 14.6824 - mean_absolute_error: 2.7814     \n",
      "Epoch 238/300\n",
      "506/506 [==============================] - 0s - loss: 14.8399 - mean_absolute_error: 2.7846     \n",
      "Epoch 239/300\n",
      "506/506 [==============================] - 0s - loss: 15.2336 - mean_absolute_error: 2.7422     \n",
      "Epoch 240/300\n",
      "506/506 [==============================] - 0s - loss: 16.0987 - mean_absolute_error: 2.8328     \n",
      "Epoch 241/300\n",
      "506/506 [==============================] - 0s - loss: 14.4822 - mean_absolute_error: 2.7190     \n",
      "Epoch 242/300\n",
      "506/506 [==============================] - 0s - loss: 14.0985 - mean_absolute_error: 2.7336     \n",
      "Epoch 243/300\n",
      "506/506 [==============================] - 0s - loss: 14.2501 - mean_absolute_error: 2.6979     \n",
      "Epoch 244/300\n",
      "506/506 [==============================] - 0s - loss: 14.6935 - mean_absolute_error: 2.7215     \n",
      "Epoch 245/300\n",
      "506/506 [==============================] - 0s - loss: 15.7575 - mean_absolute_error: 2.7883     \n",
      "Epoch 246/300\n",
      "506/506 [==============================] - 0s - loss: 13.9749 - mean_absolute_error: 2.6549     \n",
      "Epoch 247/300\n",
      "506/506 [==============================] - 0s - loss: 15.1989 - mean_absolute_error: 2.8241     \n",
      "Epoch 248/300\n",
      "506/506 [==============================] - 0s - loss: 14.4920 - mean_absolute_error: 2.7431     \n",
      "Epoch 249/300\n",
      "506/506 [==============================] - 0s - loss: 14.0819 - mean_absolute_error: 2.6838     \n",
      "Epoch 250/300\n",
      "506/506 [==============================] - 0s - loss: 14.4029 - mean_absolute_error: 2.7189     \n",
      "Epoch 251/300\n",
      "506/506 [==============================] - 0s - loss: 15.3771 - mean_absolute_error: 2.8344     \n",
      "Epoch 252/300\n",
      "506/506 [==============================] - 0s - loss: 14.9749 - mean_absolute_error: 2.7597     \n",
      "Epoch 253/300\n",
      "506/506 [==============================] - 0s - loss: 16.2462 - mean_absolute_error: 2.8875     \n",
      "Epoch 254/300\n",
      "506/506 [==============================] - 0s - loss: 15.4752 - mean_absolute_error: 2.8335     \n",
      "Epoch 255/300\n",
      "506/506 [==============================] - 0s - loss: 17.2203 - mean_absolute_error: 2.8765     \n",
      "Epoch 256/300\n",
      "506/506 [==============================] - 0s - loss: 15.9196 - mean_absolute_error: 2.8671     \n",
      "Epoch 257/300\n",
      "506/506 [==============================] - 0s - loss: 14.7076 - mean_absolute_error: 2.7736     \n",
      "Epoch 258/300\n",
      "506/506 [==============================] - 0s - loss: 14.0747 - mean_absolute_error: 2.7107     \n",
      "Epoch 259/300\n",
      "506/506 [==============================] - 0s - loss: 14.2544 - mean_absolute_error: 2.6960     \n",
      "Epoch 260/300\n",
      "506/506 [==============================] - 0s - loss: 15.2829 - mean_absolute_error: 2.7999     \n",
      "Epoch 261/300\n",
      "506/506 [==============================] - 0s - loss: 13.6808 - mean_absolute_error: 2.6192     \n",
      "Epoch 262/300\n",
      "506/506 [==============================] - 0s - loss: 15.9658 - mean_absolute_error: 2.7793     \n",
      "Epoch 263/300\n",
      "506/506 [==============================] - 0s - loss: 14.3739 - mean_absolute_error: 2.6942     \n",
      "Epoch 264/300\n",
      "506/506 [==============================] - 0s - loss: 14.5942 - mean_absolute_error: 2.7625     \n",
      "Epoch 265/300\n",
      "506/506 [==============================] - 0s - loss: 13.9003 - mean_absolute_error: 2.6768     \n",
      "Epoch 266/300\n",
      "506/506 [==============================] - 0s - loss: 17.1519 - mean_absolute_error: 2.9010     \n",
      "Epoch 267/300\n",
      "506/506 [==============================] - 0s - loss: 16.0232 - mean_absolute_error: 2.9006     \n",
      "Epoch 268/300\n",
      "506/506 [==============================] - 0s - loss: 14.2996 - mean_absolute_error: 2.6991     \n",
      "Epoch 269/300\n",
      "506/506 [==============================] - 0s - loss: 14.3304 - mean_absolute_error: 2.6808     \n",
      "Epoch 270/300\n",
      "506/506 [==============================] - 0s - loss: 17.0063 - mean_absolute_error: 2.9648     \n",
      "Epoch 271/300\n",
      "506/506 [==============================] - 0s - loss: 14.0653 - mean_absolute_error: 2.6811     \n",
      "Epoch 272/300\n",
      "506/506 [==============================] - 0s - loss: 14.5730 - mean_absolute_error: 2.6871     \n",
      "Epoch 273/300\n",
      "506/506 [==============================] - 0s - loss: 13.7717 - mean_absolute_error: 2.6598     \n",
      "Epoch 274/300\n",
      "506/506 [==============================] - 0s - loss: 14.8559 - mean_absolute_error: 2.8488     \n",
      "Epoch 275/300\n",
      "506/506 [==============================] - 0s - loss: 14.5567 - mean_absolute_error: 2.7407     \n",
      "Epoch 276/300\n",
      "506/506 [==============================] - 0s - loss: 14.7094 - mean_absolute_error: 2.7663     \n",
      "Epoch 277/300\n",
      "506/506 [==============================] - 0s - loss: 13.3397 - mean_absolute_error: 2.5934     \n",
      "Epoch 278/300\n",
      "506/506 [==============================] - 0s - loss: 16.4895 - mean_absolute_error: 2.9373     \n",
      "Epoch 279/300\n",
      "506/506 [==============================] - 0s - loss: 13.5844 - mean_absolute_error: 2.6293     \n",
      "Epoch 280/300\n",
      "506/506 [==============================] - 0s - loss: 13.8248 - mean_absolute_error: 2.6189     \n",
      "Epoch 281/300\n",
      "506/506 [==============================] - 0s - loss: 15.7258 - mean_absolute_error: 2.8095     \n",
      "Epoch 282/300\n",
      "506/506 [==============================] - 0s - loss: 13.6279 - mean_absolute_error: 2.6208     \n",
      "Epoch 283/300\n",
      "506/506 [==============================] - 0s - loss: 13.7636 - mean_absolute_error: 2.6405     \n",
      "Epoch 284/300\n",
      "506/506 [==============================] - 0s - loss: 15.2457 - mean_absolute_error: 2.8693     \n",
      "Epoch 285/300\n",
      "506/506 [==============================] - 0s - loss: 15.1336 - mean_absolute_error: 2.8237     \n",
      "Epoch 286/300\n",
      "506/506 [==============================] - 0s - loss: 14.1100 - mean_absolute_error: 2.7073     \n",
      "Epoch 287/300\n",
      "506/506 [==============================] - 0s - loss: 12.9131 - mean_absolute_error: 2.5772     \n",
      "Epoch 288/300\n",
      "506/506 [==============================] - 0s - loss: 13.7149 - mean_absolute_error: 2.6341     \n",
      "Epoch 289/300\n",
      "506/506 [==============================] - 0s - loss: 15.5297 - mean_absolute_error: 2.7795     \n",
      "Epoch 290/300\n",
      "506/506 [==============================] - 0s - loss: 13.7580 - mean_absolute_error: 2.6446     \n",
      "Epoch 291/300\n",
      "506/506 [==============================] - 0s - loss: 14.4361 - mean_absolute_error: 2.7092     \n",
      "Epoch 292/300\n",
      "506/506 [==============================] - 0s - loss: 17.9173 - mean_absolute_error: 3.0616     \n",
      "Epoch 293/300\n",
      "506/506 [==============================] - 0s - loss: 13.8715 - mean_absolute_error: 2.6711     \n",
      "Epoch 294/300\n",
      "506/506 [==============================] - 0s - loss: 14.0262 - mean_absolute_error: 2.6114     \n",
      "Epoch 295/300\n",
      "506/506 [==============================] - 0s - loss: 14.1429 - mean_absolute_error: 2.7192     \n",
      "Epoch 296/300\n",
      "506/506 [==============================] - 0s - loss: 13.2568 - mean_absolute_error: 2.5726     \n",
      "Epoch 297/300\n",
      "506/506 [==============================] - 0s - loss: 14.8270 - mean_absolute_error: 2.7958     \n",
      "Epoch 298/300\n",
      "506/506 [==============================] - 0s - loss: 13.8085 - mean_absolute_error: 2.7256     \n",
      "Epoch 299/300\n",
      "506/506 [==============================] - 0s - loss: 13.4298 - mean_absolute_error: 2.6265     \n",
      "Epoch 300/300\n",
      "506/506 [==============================] - 0s - loss: 13.2223 - mean_absolute_error: 2.5763     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277d4df0eb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/506 [==========================>...] - ETA: 0s Mean Absolute Error: 2.68 \n"
     ]
    }
   ],
   "source": [
    "#evaluate model\n",
    "score=model.evaluate(X,Y,batch_size=10,verbose=1,sample_weight=None)\n",
    "print(\" Mean Absolute Error: %.2f \" % (score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 2 - Grid Search for Optimizer Functions\n",
    "def createModel(optimizer='adam', learn_rate=0.01, momentum=0, activation='relu',dropout_rate=0.0, weight_constraint=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=13, init='normal' ,activation='relu'))\n",
    "    model.add(Dense(15, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 13)\n",
      "(99,)\n"
     ]
    }
   ],
   "source": [
    "#Downsampling the data\n",
    "X_T=X[1:100,:]\n",
    "Y_T=Y[1:100,]\n",
    "print (X_T.shape)\n",
    "print (Y_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=createModel, nb_epoch=5, batch_size=10,verbose=0)\n",
    "#kfold = KFold(n_splits=5, random_state=seed)\n",
    "#results = cross_val_score(estimator, X_T, Y_T, cv=kfold)\n",
    "\n",
    "#print(results)\n",
    "#print(\"Results: %.2f (%.2f)\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=1,scoring='neg_mean_absolute_error')\n",
    "grid_result = grid.fit(X_T, Y_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -8.197482 using {'optimizer': 'RMSprop'}\n",
      "-12.320509 (2.327505) with: {'optimizer': 'SGD'}\n",
      "-8.197482 (2.333108) with: {'optimizer': 'RMSprop'}\n",
      "-12.712444 (2.883628) with: {'optimizer': 'Adagrad'}\n",
      "-13.180811 (5.706599) with: {'optimizer': 'Adadelta'}\n",
      "-10.621854 (4.115492) with: {'optimizer': 'Adam'}\n",
      "-12.066472 (4.864682) with: {'optimizer': 'Adamax'}\n",
      "-10.179547 (0.256207) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "learn_rate = [0.1, 0.2, 0.3]\n",
    "momentum = [0.6, 0.8, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=1,scoring='neg_mean_absolute_error')\n",
    "grid_result = grid.fit(X_T, Y_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -7.092687 using {'momentum': 0.9, 'learn_rate': 0.1}\n",
      "-15.618842 (3.863621) with: {'momentum': 0.6, 'learn_rate': 0.1}\n",
      "-7.193136 (1.605399) with: {'momentum': 0.8, 'learn_rate': 0.1}\n",
      "-7.092687 (3.209418) with: {'momentum': 0.9, 'learn_rate': 0.1}\n",
      "-9.859799 (2.109321) with: {'momentum': 0.6, 'learn_rate': 0.2}\n",
      "-9.905955 (4.056334) with: {'momentum': 0.8, 'learn_rate': 0.2}\n",
      "-12.883302 (5.787058) with: {'momentum': 0.9, 'learn_rate': 0.2}\n",
      "-8.984422 (1.669774) with: {'momentum': 0.6, 'learn_rate': 0.3}\n",
      "-10.794084 (4.178972) with: {'momentum': 0.8, 'learn_rate': 0.3}\n",
      "-13.768197 (4.651002) with: {'momentum': 0.9, 'learn_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=1, scoring='neg_mean_absolute_error')\n",
    "grid_result = grid.fit(X_T, Y_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -9.873848 using {'activation': 'hard_sigmoid'}\n",
      "-13.145561 (6.581714) with: {'activation': 'softmax'}\n",
      "-10.305245 (2.635532) with: {'activation': 'softplus'}\n",
      "-12.234603 (5.425744) with: {'activation': 'softsign'}\n",
      "-10.034799 (3.644700) with: {'activation': 'relu'}\n",
      "-11.358992 (4.708074) with: {'activation': 'tanh'}\n",
      "-13.903073 (2.252260) with: {'activation': 'sigmoid'}\n",
      "-9.873848 (4.250643) with: {'activation': 'hard_sigmoid'}\n",
      "-10.906476 (4.238910) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4c055e5d2bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight_constraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_T\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# summarize results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[1;31m# get trainable weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mtrainable_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollect_trainable_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mtraining_updates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, params, constraints, loss)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mtf_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_string_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             warnings.warn('Could not automatically initialize variable, '\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    997\u001b[0m                 run_metadata):\n\u001b[1;32m    998\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1048\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1049\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2,3]\n",
    "dropout_rate = [0.0, 0.1, 0.3, 0.5, 0.8]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=1, scoring='neg_mean_absolute_error')\n",
    "grid_result = grid.fit(X_T, Y_T)# summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -9.873848 using {'activation': 'hard_sigmoid'}\n",
      "-13.145561 (6.581714) with: {'activation': 'softmax'}\n",
      "-10.305245 (2.635532) with: {'activation': 'softplus'}\n",
      "-12.234603 (5.425744) with: {'activation': 'softsign'}\n",
      "-10.034799 (3.644700) with: {'activation': 'relu'}\n",
      "-11.358992 (4.708074) with: {'activation': 'tanh'}\n",
      "-13.903073 (2.252260) with: {'activation': 'sigmoid'}\n",
      "-9.873848 (4.250643) with: {'activation': 'hard_sigmoid'}\n",
      "-10.906476 (4.238910) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KerasRegressor wrapper\n",
    "def create_model_3():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='hard_sigmoid'))\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation ='hard_sigmoid'))\n",
    "    optimizer = SGD(lr=0.1, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KerasRegressor' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9c6c6145d2b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# evaluate model with standardized dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_model_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#results = cross_val_score(estimator, X_T, Y_T, cv=kfold)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[1;31m# shallow copy of steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtosequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\adity\\.conda\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36mtosequence\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'KerasRegressor' object is not iterable"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=create_model_3, nb_epoch=100, batch_size=5, verbose=0)\n",
    "pipeline = Pipeline(estimator)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "#results = cross_val_score(estimator, X_T, Y_T, cv=kfold)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# evaluate model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=create_model_3, epochs=5, batch_size=10, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X_T, Y_T, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smaller hidden layer\n",
    "def create_small_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='hard_sigmoid'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='hard_sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=create_small_model, epochs=5, batch_size=10, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X_T, Y_T, cv=kfold)\n",
    "print(\"Smaller: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# deeper model\n",
    "def create_large_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='hard_sigmoid'))\n",
    "    model.add(Dense(7, kernel_initializer='normal', activation='hard_sigmoid'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    #model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=create_large_model, epochs=5, batch_size=10, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=5, random_state=seed)\n",
    "results = cross_val_score(pipeline, X_T, Y_T, cv=kfold)\n",
    "print(\"Deeper: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wider hidden layer\n",
    "def create_wider_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='hard_sigmoid'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='hard_sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=create_wider_model, epochs=5, batch_size=10, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X_T, Y_T, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
